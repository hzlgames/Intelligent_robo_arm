# 视觉协同跟随与沿指向运动：算法与接口设计

更新时间：2025-12-25

本文目标：为未来“计算机视觉 + 机械臂”联动准备一套**可复用、可解释、可逐步增强**的接口与控制算法，使机械臂能够：
- 跟随画面中的物体（目标在画面中移动时，末端随之调整）
- 跟随“指向变化”（指尖落点 / 指向射线变化时，末端随之调整）
- 沿“指向方向”前进/后退（沿射线推进/拉远）

---

## 1. 数据流（推荐架构）

```
Camera Frame
  └─ Vision Module（检测/分割/手势）
       └─ VisualObservation（像素目标/深度/指向射线）
            └─ VisualServoController（控制量计算）
                 └─ VisualServoOutput（归一化 XYZ+Pitch）
                      └─ JogController（积分 + IK + 下发）
```

关键思想：视觉模块只负责**输出观测**，运动控制模块只负责**把观测变成控制量**，二者解耦。

### 1.1 当前工程落地位置（代码对应）

本架构已落地到工程中，对应关系如下（便于你后续查代码/扩展模块）：

- **取帧与 HUD**：`preview.cpp` / `device.cpp`
  - 预览线程持续渲染；同时提供“复制最新一帧 RGB32”的旁路接口给视觉线程（只取最新帧，允许丢帧）。
- **视觉线程（多模式识别）**：`VisionService.h/.cpp`
  - `Auto / BrightestPoint / ColorTrack / Aruco / Detector / Hand` 多模式输出 `VisualObservation`。
- **检测器封装（ONNX）**：`VisionDetector.h/.cpp`
  - 当前默认后端为 OpenCV DNN；通过“Win32 读文件到内存再加载”规避中文路径问题。
- **几何基础层**：`VisionGeometry.h/.cpp`
  - 像素→射线、射线→平面交点、由 ArUco pose 推桌面平面等。
- **控制器（观测→控制量）**：`VisualServoTypes.h` / `VisualServoController.h/.cpp`
  - 只关心 `VisualObservation`，不绑定具体识别算法。
- **主界面集成**：`智能机械臂Dlg.cpp`
  - 在 `StartMainPreview/StopMainPreview` 绑定/解绑 `VisionService` 的 Preview 源；
  - 在 `OnTimer` 中按帧尺寸刷新 `CameraIntrinsics`（先用近似值跑通闭环，未来由真实标定替换）；
  - 支持“视频区点击生成观测”并正确处理 letterbox（黑边）映射。
- **参数持久化/导入导出**：`SettingsIo.cpp`
  - 视觉参数统一纳入 `.ini`（`Vision` / `Vision\\Aruco` / `Vision\\Detector`），并支持导入后热更新。

### 1.2 线程与一致性（为什么这样设计）

- 预览线程（Media Foundation 回调）不做重计算，避免掉帧。
- 视觉线程“处理跟不上就丢旧帧”，只保留最新帧，保证低延迟。
- Detector 参数支持运行中更新，内部做互斥保护，避免导入 `.ini` 时与推理并发导致崩溃。

---

## 2. 坐标约定（必须统一）

### 2.1 像素坐标
- \(u\) 向右为正
- \(v\) 向下为正

### 2.2 相机坐标系 Cam（建议按 OpenCV）
- \(X_{cam}\) 向右为正
- \(Y_{cam}\) 向下为正
- \(Z_{cam}\) 向前（光轴）为正

### 2.3 机械臂 Base 坐标系（本项目约定）
- \(X\) 向右
- \(Y\) 向前
- \(Z\) 向上

> 当前实现提供了一个“默认 Cam→Base 映射”，用于先跑通闭环；
> 未来应当通过相机外参（相机相对末端的旋转/平移）替换为精确变换矩阵。

### 2.4 UI 点击坐标 → 帧坐标（重要：避免“点哪不去哪”）

主界面视频控件通常会存在 **letterbox 黑边**（画面等比缩放居中），因此：
- UI 点击点（控件坐标）不能直接当成帧像素坐标；
- 必须先计算“帧在控件中的显示矩形”，再做归一化映射到帧坐标系。

该逻辑已在主界面点击调试中落地，保证：
- 你点在黑边不会误触发；
- 你点在画面上某点，生成的 `(u,v)` 与 HUD/取帧坐标系一致。

---

## 3. 接口定义（已落地到代码）

文件：
- `VisualServoTypes.h`
- `VisualServoController.h/.cpp`

### 3.1 视觉观测输入：`VisualObservation`
视觉模块每帧/每次更新，向控制器提供：
- 目标像素点 `(u,v)`（例如目标中心点/指尖落点/检测框中心）
- 可选深度 `depthMm`
- 可选指向射线 `(rayX, rayY, rayZ)`（Cam 坐标系单位向量）
- 可选置信度 `confidence`
- 时间戳 `tickMs = GetTickCount64()`

### 3.2 控制器输出：`VisualServoOutput`
控制器输出归一化指令：
- `x,y,z,pitch ∈ [-1,1]`
- `active`：是否有效
- `errU, errV`：像素误差（用于 HUD/日志）
- `reason`：解释文本

### 3.3 控制模式：`VisualServoMode`
- `CenterTarget`：只做“居中”
- `FollowRay`：沿射线前进/后退（可与居中并用）
- `LookAndMove`：先居中，居中后再推进（抓取常用）

---

## 4. 控制算法（核心）

### 4.1 像素误差 → 平移速度（Look 部分）
若已知相机内参（针孔模型）：
- 误差：\(e_u = u - c_x,\ e_v = v - c_y\)
- 近似平移速度：
  - \(v_{x,cam} = k \cdot e_u \cdot (depth / f_x)\)
  - \(v_{y,cam} = k \cdot e_v \cdot (depth / f_y)\)

若无深度/无内参：退化为经验映射 \(v \approx k \cdot e\)，靠闭环迭代逼近。

### 4.2 沿指向方向前进/后退（Move 部分）
两种实现路径（代码已在 `VisualServoController::ComputeOutput` 中落地）：
- **射线运动 (Ray Motion)**：当 `obs.hasRay` 为真时，算法会归一化射线向量 $\vec{R}$。控制量 $\vec{v}_{cam} = \text{raySpeed} \cdot \text{advance} \cdot \vec{R}$。这允许机械臂“指哪打哪”。
- **深度距离闭环 (Depth Closed-loop)**：当无射线但有深度时，计算误差 $d_z = \text{depth} - \text{desiredDepth}$。通过比例增益 $k_d$ 生成沿光轴 $Z$ 的速度。
- **推进抑制逻辑**：在 `LookAndMove` 模式下，算法会实时监测像素误差。只有当误差 $e_u, e_v$ 进入双倍死区范围内（即目标已基本居中），才会激活 `advance` 推进分量，防止盲目推进导致目标丢失。

### 4.3 安全与稳定
控制器内置：
- 观测超时 `maxObsAgeMs`：防止旧数据“拖尾”
- 像素死区 `deadbandPx`：去抖
- 低通滤波 `filterAlpha`：减轻抖动
- 置信度阈值：过滤误检

### 4.4 参数可调与可复现（工程化要求）

为了让“实验室/宿舍/不同电脑”都能复现一致效果，建议所有关键参数都必须：
- **可持久化**：退出程序后仍保留；
- **可导入导出**：用 `.ini` 一键同步；
- **可解释**：日志/HUD 能说明“本次为什么 active / 为什么 inactive”。

当前已把视觉相关参数纳入导入导出（见 `SettingsIo.cpp` 对应段），包含：
- 通用：模式、处理周期、采样步长、平滑系数等；
- ArUco：marker 边长（影响深度尺度）；
- Detector：ONNX 路径、输入尺寸、conf/nms 阈值等。

---

## 5. 未来增强点（不会破坏接口）

### 5.1 精确 Cam→Base 变换
当前采用默认映射（先跑通闭环），未来建议：
- 引入 `T_base_cam`（4x4）
- 将 `v_cam` 通过旋转矩阵变换为 `v_base`

### 5.2 视觉锁定与状态机
建议把“锁定/取消/急停/丢失回退”等做成明确状态机：
- Acquire → Track → Approach → Grasp → Retreat

### 5.3 多目标选择/优先级
视觉模块可输出多个候选，控制器只吃“已锁定的那个目标”即可，接口无需变化。


